{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b489991",
   "metadata": {},
   "source": [
    "# Fase 3 script clasification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b5e47c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jsonx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcopy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m copy\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjsonx\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jsonx'"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "import math\n",
    "import jsonx\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import unicodedata\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles.borders import Border, Side\n",
    "from openpyxl.utils import get_column_letter, range_boundaries\n",
    "\n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from expresiones import OCR_PATTERNS\n",
    "\n",
    "# ———RUTAS y UMBRALES ———\n",
    "MODEL_PATH      = r'C:\\Users\\juans\\Documents\\proarchitecg\\version_2_docker\\model_clasification_image_v2\\runs\\classify\\person_cls\\weights\\best.pt'\n",
    "IMAGES_ROOT     = r'C:\\Users\\juans\\Documents\\proarchitecg\\version_2_docker\\imagenes_por_doc\\LETRA A\\ACTA N° 70\\19\\Adrada Aguilar Carlos Ivan.json'\n",
    "OCR_ROOT        = r'D:\\historias\\dev\\ocr_por_doc\\LETRA A\\ACTA N° 70\\19\\Adrada Aguilar Carlos Ivan.json'\n",
    "OUTPUT_FILE     = r'C:\\Users\\juans\\Documents\\proarchitecg\\version_2_docker\\resultados_completos_v_final.xlsx'\n",
    "TEMPLATE_PATH   = r'C:\\Users\\juans\\Downloads\\dev_prev\\FORMATO HOJA DE CONTROL DOCUMENTAL.xlsx'\n",
    "OUTPUT_DIR_CTRL = r'C:\\Users\\juans\\Documents\\proarchitecg\\version_2_docker\\model_clasification_image_v2\\answer\\hojas_control'\n",
    "\n",
    "CONF_THRESH = 0.5\n",
    "SCORING_MIN = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc854387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- UTILIDADES -----------------\n",
    "def normalize_text(text: str) -> str:\n",
    "    text = unicodedata.normalize(\"NFKD\", text).encode(\"ASCII\", \"ignore\").decode()\n",
    "    return re.sub(r\"\\s+\", \"\", text).strip().lower()\n",
    "\n",
    "def extract_page_number(file_name: str) -> float:\n",
    "    match = (re.search(r\"pagina[_-]?(\\d+)\", file_name, re.IGNORECASE)\n",
    "            or re.search(r\"(\\d+)\", file_name))\n",
    "    return int(match.group(1)) if match else math.nan\n",
    "\n",
    "def compile_dict(raw_dict):\n",
    "    compiled = {}\n",
    "    for label, patterns in raw_dict.items():\n",
    "        patterns = patterns if isinstance(patterns, list) else [patterns]\n",
    "        compiled[label] = [\n",
    "            pattern if isinstance(pattern, re.Pattern)\n",
    "            else re.compile(rf\"\\b{pattern}\\b\", re.IGNORECASE | re.VERBOSE)\n",
    "            for pattern in patterns\n",
    "        ]\n",
    "    return compiled\n",
    "\n",
    "\n",
    "def fuzzy_ocr_label(text: str, patterns_by_label: dict, threshold: int = 75):\n",
    "    best_label, best_score = \"\", 0.0\n",
    "    for label, pattern_list in patterns_by_label.items():\n",
    "        for pattern in pattern_list:\n",
    "            score = fuzz.partial_ratio(text, pattern)\n",
    "            if score > best_score:\n",
    "                best_label, best_score = label, score\n",
    "    if best_score >= threshold:\n",
    "        return best_label, best_score / 100.0\n",
    "    return \"\", 0.0\n",
    "\n",
    "\n",
    "def visual_predict(model, image_path: str, strict: bool = True):\n",
    "    result = model.predict(source=image_path, device=\"cpu\", task=\"classify\", verbose=False)[0]\n",
    "    probabilities = getattr(result, \"probs\", None)\n",
    "    arr = probabilities.data.tolist() if hasattr(probabilities, \"data\") else list(probabilities or [])\n",
    "    if not arr or (strict and max(arr) < CONF_THRESH):\n",
    "        return None, (max(arr) if arr else 0.0)\n",
    "    index = arr.index(max(arr))\n",
    "    return model.names[index], max(arr)\n",
    "\n",
    "# ----------------- OCR / IMÁGENES -----------------\n",
    "def find_persona_images(root_path: str):\n",
    "    persona_images = {}\n",
    "    for dirpath, _, files in os.walk(root_path):\n",
    "        images = [\n",
    "            os.path.join(dirpath, file_name)\n",
    "            for file_name in files\n",
    "            if file_name.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "        ]\n",
    "        if images:\n",
    "            persona_name = normalize_text(os.path.basename(dirpath))\n",
    "            persona_images.setdefault(persona_name, []).extend(images)\n",
    "    return persona_images\n",
    "\n",
    "\n",
    "def build_ocr_map(root_path: str):\n",
    "    json_map = {}\n",
    "    for dirpath, _, files in os.walk(root_path):\n",
    "        for file_name in files:\n",
    "            if file_name.lower().endswith(\".json\"):\n",
    "                normalized_name = normalize_text(os.path.splitext(file_name)[0])\n",
    "                json_map[normalized_name] = os.path.join(dirpath, file_name)\n",
    "    return json_map\n",
    "\n",
    "\n",
    "def match_json_for_persona(json_map, persona_name, threshold=70):\n",
    "    if persona_name in json_map:\n",
    "        return json_map[persona_name]\n",
    "\n",
    "    best_score, best_key = 0, None\n",
    "    for json_key in json_map:\n",
    "        score = fuzz.partial_ratio(persona_name, json_key)\n",
    "        if score > best_score:\n",
    "            best_score, best_key = score, json_key\n",
    "    if best_score >= threshold:\n",
    "        return json_map[best_key]\n",
    "    return None\n",
    "\n",
    "\n",
    "OCR_REGEX = compile_dict(OCR_PATTERNS)\n",
    "\n",
    "\n",
    "def classify(text, model, image_path):\n",
    "    text = normalize_text(text or \"\")\n",
    "\n",
    "    label, confidence = visual_predict(model, image_path, strict=True)\n",
    "    if label:\n",
    "        return label, confidence, \"visual\"\n",
    "\n",
    "    scores = {doc_type: 0 for doc_type in OCR_REGEX}\n",
    "    for doc_type, pattern_list in OCR_REGEX.items():\n",
    "        for pattern in pattern_list:\n",
    "            if pattern.search(text):\n",
    "                scores[doc_type] += 1\n",
    "\n",
    "    thresholds = {doc_type: max(1, len(OCR_REGEX[doc_type]) // 2) for doc_type in OCR_REGEX}\n",
    "    best_doc_type, count = max(scores.items(), key=lambda x: x[1])\n",
    "    if count >= thresholds[best_doc_type]:\n",
    "        return best_doc_type, count / len(OCR_REGEX[best_doc_type]), \"ocr_scoring\"\n",
    "\n",
    "    for doc_type, pattern_list in OCR_REGEX.items():\n",
    "        if any(pattern.search(text) for pattern in pattern_list):\n",
    "            return doc_type, 1.0, \"ocr_regex\"\n",
    "\n",
    "    simple = {doc_type: [pattern.pattern for pattern in OCR_REGEX[doc_type]] for doc_type in OCR_REGEX}\n",
    "    label_fuzzy, confidence_fuzzy = fuzzy_ocr_label(text, simple)\n",
    "    if label_fuzzy:\n",
    "        return label_fuzzy, confidence_fuzzy, \"ocr_fuzzy\"\n",
    "\n",
    "    return \"\", 0.0, \"none\"\n",
    "\n",
    "# ----------------- EXCEL -----------------\n",
    "def copy_row_format(sheet, src_row, tgt_row, max_col=13, row_height=48):\n",
    "    sheet.row_dimensions[tgt_row].height = row_height\n",
    "    thin = Side(border_style=\"thin\", color=\"000000\")\n",
    "    full_border = Border(left=thin, right=thin, top=thin, bottom=thin)\n",
    "\n",
    "    for col in range(1, max_col + 1):\n",
    "        src = sheet.cell(row=src_row, column=col)\n",
    "        tgt = sheet.cell(row=tgt_row, column=col)\n",
    "        if src.has_style:\n",
    "            tgt.font = copy(src.font)\n",
    "            tgt.fill = copy(src.fill)\n",
    "            tgt.number_format = copy(src.number_format)\n",
    "            tgt.protection = copy(src.protection)\n",
    "            tgt.alignment = copy(src.alignment)\n",
    "        tgt.border = full_border\n",
    "\n",
    "    for merged in list(sheet.merged_cells.ranges):\n",
    "        if merged.min_row == src_row == merged.max_row:\n",
    "            c1 = get_column_letter(merged.min_col)\n",
    "            c2 = get_column_letter(merged.max_col)\n",
    "            sheet.merge_cells(f\"{c1}{tgt_row}:{c2}{tgt_row}\")\n",
    "\n",
    "\n",
    "def remove_holes(sheet, hole_ranges):\n",
    "    parsed = []\n",
    "    for rng in hole_ranges:\n",
    "        min_col, min_row, max_col, max_row = range_boundaries(rng)\n",
    "        parsed.append((min_row, max_row, min_col, max_col))\n",
    "\n",
    "    to_unmerge = []\n",
    "    for merged in list(sheet.merged_cells.ranges):\n",
    "        for min_row, max_row, min_col, max_col in parsed:\n",
    "            if not (merged.max_row < min_row or merged.min_row > max_row\n",
    "                    or merged.max_col < min_col or merged.min_col > max_col):\n",
    "                to_unmerge.append(merged.coord)\n",
    "                break\n",
    "    for coord in to_unmerge:\n",
    "        sheet.unmerge_cells(coord)\n",
    "\n",
    "    for rng in hole_ranges:\n",
    "        for row in sheet[rng]:\n",
    "            for cell in row:\n",
    "                cell.value = None\n",
    "\n",
    "\n",
    "def generate_control_sheet(persona_df, persona_name):\n",
    "    output_path = os.path.join(OUTPUT_DIR_CTRL, f\"{persona_name}_hoja_control.xlsx\")\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"⚠️ Ya existe hoja de control para '{persona_name}', omitiendo.\")\n",
    "        return\n",
    "\n",
    "    workbook = load_workbook(TEMPLATE_PATH)\n",
    "    sheet = workbook.active\n",
    "    START_ROW = 18\n",
    "\n",
    "    holes = [\"B57:B59\", \"C57:F59\", \"D60:F60\"]\n",
    "    remove_holes(sheet, holes)\n",
    "\n",
    "    for index, record in enumerate(persona_df.sort_values(\"posicion\").itertuples(), start=1):\n",
    "        row = START_ROW + index - 1\n",
    "        sheet.cell(row=row, column=1, value=index)                   # A\n",
    "        sheet.cell(row=row, column=5, value=record.predicted)        # E\n",
    "        sheet.cell(row=row, column=6, value=int(record.posicion))    # F\n",
    "        sheet.cell(row=row, column=7, value=int(record.posicion))    # G\n",
    "\n",
    "    workbook.save(output_path)\n",
    "    print(\"✅ Control inmediato:\", output_path)\n",
    "\n",
    "# ----------------- MAIN -----------------\n",
    "def main():\n",
    "    os.makedirs(OUTPUT_DIR_CTRL, exist_ok=True)\n",
    "    model = YOLO(MODEL_PATH)\n",
    "\n",
    "    json_map = build_ocr_map(OCR_ROOT)\n",
    "    persona_images = find_persona_images(IMAGES_ROOT)\n",
    "\n",
    "    all_rows, global_id = [], 1\n",
    "\n",
    "    for persona_key, image_paths in persona_images.items():\n",
    "        print(f\"\\nProcesando persona '{persona_key}' con {len(image_paths)} imágenes…\")\n",
    "        text_lookup = {}\n",
    "        persona_records = []\n",
    "\n",
    "        json_path = match_json_for_persona(json_map, persona_key)\n",
    "        if json_path:\n",
    "            with open(json_path, encoding=\"utf-8\") as file:\n",
    "                data = json.load(file)\n",
    "            records = data if isinstance(data, list) else [data]\n",
    "            for record in records:\n",
    "                page = record.get(\"pagina\")\n",
    "                image_from_record = record.get(\"imagen\", \"\")\n",
    "                text = record.get(\"texto\", \"\")\n",
    "                if page is not None:\n",
    "                    text_lookup[page] = text\n",
    "                if image_from_record:\n",
    "                    text_lookup[os.path.basename(image_from_record)] = text\n",
    "\n",
    "        for image_path in sorted(image_paths, key=extract_page_number):\n",
    "            page = extract_page_number(image_path)\n",
    "            text = (text_lookup.get(os.path.basename(image_path))\n",
    "                    or text_lookup.get(page, \"\"))\n",
    "            label, score, layer = classify(text, model, image_path)\n",
    "\n",
    "            record = {\n",
    "                \"id\":        global_id,\n",
    "                \"persona\":   persona_key,\n",
    "                \"imagen\":    image_path,\n",
    "                \"posicion\":  page,\n",
    "                \"predicted\": label,\n",
    "                \"score\":     score,\n",
    "                \"layer\":     layer,\n",
    "            }\n",
    "            all_rows.append(record)\n",
    "            persona_records.append(record)\n",
    "            global_id += 1\n",
    "\n",
    "        if persona_records:\n",
    "            persona_df = pd.DataFrame(persona_records)\n",
    "            persona_df[\"correct\"] = persona_df[\"persona\"] == persona_df[\"predicted\"]\n",
    "            generate_control_sheet(persona_df, persona_key)\n",
    "\n",
    "    print(\"\\n⏳ Generando DataFrame y guardando\", OUTPUT_FILE)\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    df[\"correct\"] = df[\"persona\"] == df[\"predicted\"]\n",
    "    df.to_excel(OUTPUT_FILE, index=False)\n",
    "    print(\"✅ Consolidado en\", OUTPUT_FILE)\n",
    "\n",
    "    START_ROW = 18\n",
    "    for persona_name, group in df[df[\"predicted\"] != \"\"].groupby(\"persona\"):\n",
    "        workbook = load_workbook(TEMPLATE_PATH)\n",
    "        sheet = workbook.active\n",
    "\n",
    "        footer = None\n",
    "        for row in sheet.iter_rows(min_row=START_ROW, max_row=sheet.max_row):\n",
    "            for cell in row:\n",
    "                if isinstance(cell.value, str) and \"NOMBRE Y APELLIDOS\" in cell.value.upper():\n",
    "                    footer = cell.row\n",
    "                    break\n",
    "            if footer:\n",
    "                break\n",
    "        if not footer:\n",
    "            footer = START_ROW + 38\n",
    "\n",
    "        template_rows = footer - START_ROW\n",
    "        num_pages = len(group)\n",
    "        if num_pages > template_rows:\n",
    "            extra = num_pages - template_rows\n",
    "            sheet.insert_rows(footer, amount=extra)\n",
    "            src_row = footer - 1\n",
    "            for i in range(extra):\n",
    "                dst_row = footer + i\n",
    "                sheet.row_dimensions[dst_row].height = sheet.row_dimensions[src_row].height\n",
    "                for col in (5, 6, 7):\n",
    "                    src = sheet.cell(row=src_row, column=col)\n",
    "                    dst = sheet.cell(row=dst_row, column=col)\n",
    "                    dst.font = copy(src.font)\n",
    "                    dst.border = copy(src.border)\n",
    "                    dst.fill = copy(src.fill)\n",
    "                    dst.alignment = copy(src.alignment)\n",
    "                    dst.number_format = src.number_format\n",
    "\n",
    "        for index, record in enumerate(group.sort_values(\"posicion\").itertuples()):\n",
    "            row = START_ROW + index\n",
    "            sheet.cell(row=row, column=5, value=record.predicted)\n",
    "            sheet.cell(row=row, column=6, value=int(record.posicion))\n",
    "            sheet.cell(row=row, column=7, value=int(record.posicion))\n",
    "\n",
    "        out = os.path.join(OUTPUT_DIR_CTRL, f\"{persona_name}_hoja_control.xlsx\")\n",
    "        workbook.save(out)\n",
    "        print(\"✅ Control:\", out)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b054130",
   "metadata": {},
   "source": [
    "# Orden diferente; primero Regex, Modelo visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa3b70e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import unicodedata\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles.borders import Border, Side\n",
    "from openpyxl.utils import get_column_letter, range_boundaries\n",
    "\n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from express import OCR_PATTERN as OCR_PATTERNS\n",
    "\n",
    "# ———RUTAS y UMBRALES ———\n",
    "MODEL_PATH      = r'C:\\Users\\juans\\Documents\\proarchitecg\\version_2_docker\\model_clasification_image_v2\\runs\\classify\\person_cls\\weights\\best.pt'\n",
    "IMAGES_ROOT     = r'D:\\historias\\dev\\imagenes_por_doc\\LETRA A\\ACTA N° 70\\10'\n",
    "OCR_ROOT        = r'D:\\historias\\dev\\ocr_por_doc\\LETRA A\\ACTA N° 70\\10'\n",
    "OUTPUT_FILE     = r'C:\\Users\\juans\\Documents\\proarchitecg\\version_2_docker\\resultados_completos_v_final.xlsx'\n",
    "TEMPLATE_PATH   = r'C:\\Users\\juans\\Downloads\\dev_prev\\FORMATO HOJA DE CONTROL DOCUMENTAL.xlsx'\n",
    "OUTPUT_DIR_CTRL = r'C:\\Users\\juans\\Downloads\\define\\answer'\n",
    "\n",
    "CONF_THRESH = 0.5\n",
    "SCORING_MIN = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11ba8b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando persona 'acevedo rodriguez olga lisseth' con 33 imágenes…\n",
      "✅ Control inmediato: C:\\Users\\juans\\Downloads\\define\\answer\\acevedo rodriguez olga lisseth_hoja_de_control.xlsx\n",
      "\n",
      "Procesando persona 'acevedo rodriguez sandra marley' con 63 imágenes…\n",
      "✅ Control inmediato: C:\\Users\\juans\\Downloads\\define\\answer\\acevedo rodriguez sandra marley_hoja_de_control.xlsx\n",
      "\n",
      "Procesando persona 'acevedo sanchez cynthia paola' con 31 imágenes…\n",
      "✅ Control inmediato: C:\\Users\\juans\\Downloads\\define\\answer\\acevedo sanchez cynthia paola_hoja_de_control.xlsx\n",
      "\n",
      "Procesando persona 'acevedo sanchez dora lid' con 18 imágenes…\n",
      "✅ Control inmediato: C:\\Users\\juans\\Downloads\\define\\answer\\acevedo sanchez dora lid_hoja_de_control.xlsx\n",
      "\n",
      "Procesando persona 'acevedo sanchez steffi rosbenisa' con 34 imágenes…\n",
      "✅ Control inmediato: C:\\Users\\juans\\Downloads\\define\\answer\\acevedo sanchez steffi rosbenisa_hoja_de_control.xlsx\n",
      "\n",
      "Procesando persona 'acevedo serna catalina' con 31 imágenes…\n",
      "✅ Control inmediato: C:\\Users\\juans\\Downloads\\define\\answer\\acevedo serna catalina_hoja_de_control.xlsx\n",
      "\n",
      "Procesando persona 'acevedo suarez carola' con 2 imágenes…\n",
      "✅ Control inmediato: C:\\Users\\juans\\Downloads\\define\\answer\\acevedo suarez carola_hoja_de_control.xlsx\n",
      "\n",
      "Procesando persona 'acevedo vallejo joaquin emilio' con 11 imágenes…\n",
      "✅ Control inmediato: C:\\Users\\juans\\Downloads\\define\\answer\\acevedo vallejo joaquin emilio_hoja_de_control.xlsx\n",
      "\n",
      "Procesando persona 'acevedo vega yudy liliana' con 74 imágenes…\n",
      "✅ Control inmediato: C:\\Users\\juans\\Downloads\\define\\answer\\acevedo vega yudy liliana_hoja_de_control.xlsx\n",
      "\n",
      "Procesando persona 'acevedo vesga pedro pablo' con 24 imágenes…\n",
      "✅ Control inmediato: C:\\Users\\juans\\Downloads\\define\\answer\\acevedo vesga pedro pablo_hoja_de_control.xlsx\n",
      "\n",
      "Procesando persona 'achipiz achipiz catalina maria' con 22 imágenes…\n",
      "✅ Control inmediato: C:\\Users\\juans\\Downloads\\define\\answer\\achipiz achipiz catalina maria_hoja_de_control.xlsx\n",
      "\n",
      "Procesando persona 'achito lubiaza alberto' con 13 imágenes…\n",
      "✅ Control inmediato: C:\\Users\\juans\\Downloads\\define\\answer\\achito lubiaza alberto_hoja_de_control.xlsx\n",
      "\n",
      "⏳ Generando DataFrame y guardando C:\\Users\\juans\\Documents\\proarchitecg\\version_2_docker\\resultados_completos_v_final.xlsx\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\juans\\\\Documents\\\\proarchitecg\\\\version_2_docker\\\\resultados_completos_v_final.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 317\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Control:\u001b[39m\u001b[38;5;124m\"\u001b[39m, out)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[34], line 267\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    265\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_rows)\n\u001b[0;32m    266\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrect\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpersona\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 267\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUTPUT_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Consolidado en\u001b[39m\u001b[38;5;124m\"\u001b[39m, OUTPUT_FILE)\n\u001b[0;32m    270\u001b[0m START_ROW \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m18\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\juans\\anaconda3\\envs\\clasificador_docs\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\juans\\anaconda3\\envs\\clasificador_docs\\lib\\site-packages\\pandas\\core\\generic.py:2436\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2423\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2425\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2426\u001b[0m     df,\n\u001b[0;32m   2427\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2434\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2435\u001b[0m )\n\u001b[1;32m-> 2436\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2438\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\juans\\anaconda3\\envs\\clasificador_docs\\lib\\site-packages\\pandas\\io\\formats\\excel.py:943\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    941\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 943\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\juans\\anaconda3\\envs\\clasificador_docs\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:61\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     59\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juans\\anaconda3\\envs\\clasificador_docs\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1246\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1243\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1244\u001b[0m )\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\juans\\anaconda3\\envs\\clasificador_docs\\lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\juans\\\\Documents\\\\proarchitecg\\\\version_2_docker\\\\resultados_completos_v_final.xlsx'"
     ]
    }
   ],
   "source": [
    "# ----------------- UTILIDADES -----------------\n",
    "def extract_page_number(file_name: str) -> float:\n",
    "    match = (re.search(r\"pagina[_-]?(\\d+)\", file_name, re.IGNORECASE)\n",
    "            or re.search(r\"(\\d+)\", file_name))\n",
    "    return int(match.group(1)) if match else math.nan\n",
    "\n",
    "def compile_dict(raw_dict):\n",
    "    compiled = {}\n",
    "    for label, patterns in raw_dict.items():\n",
    "        patterns = patterns if isinstance(patterns, list) else [patterns]\n",
    "        compiled[label] = [\n",
    "            pattern if isinstance(pattern, re.Pattern)\n",
    "            else re.compile(rf\"\\b{pattern}\\b\", re.IGNORECASE | re.VERBOSE)\n",
    "            for pattern in patterns\n",
    "        ]\n",
    "    return compiled\n",
    "\n",
    "\n",
    "def fuzzy_ocr_label(text: str, patterns_by_label: dict, threshold: int = 75):\n",
    "    best_label, best_score = \"\", 0.0\n",
    "    for label, pattern_list in patterns_by_label.items():\n",
    "        for pattern in pattern_list:\n",
    "            score = fuzz.partial_ratio(text, pattern)\n",
    "            if score > best_score:\n",
    "                best_label, best_score = label, score\n",
    "    if best_score >= threshold:\n",
    "        return best_label, best_score / 100.0\n",
    "    return \"\", 0.0\n",
    "\n",
    "\n",
    "def visual_predict(model, image_path: str, strict: bool = True):\n",
    "    result = model.predict(source=image_path, device=\"cpu\", task=\"classify\", verbose=False)[0]\n",
    "    probabilities = getattr(result, \"probs\", None)\n",
    "    arr = probabilities.data.tolist() if hasattr(probabilities, \"data\") else list(probabilities or [])\n",
    "    if not arr or (strict and max(arr) < CONF_THRESH):\n",
    "        return None, (max(arr) if arr else 0.0)\n",
    "    index = arr.index(max(arr))\n",
    "    return model.names[index], max(arr)\n",
    "\n",
    "# ----------------- OCR / IMÁGENES -----------------\n",
    "def normalize_filename(name: str) -> str:\n",
    "    name = unicodedata.normalize(\"NFKD\", name).encode(\"ASCII\", \"ignore\").decode()\n",
    "    return re.sub(r\"\\s+\", \" \", name).strip().lower()\n",
    "\n",
    "\n",
    "def find_persona_images(root_path: str):\n",
    "    persona_images = {}\n",
    "    display_names = {}\n",
    "    for dirpath, _, files in os.walk(root_path):\n",
    "        images = [\n",
    "            os.path.join(dirpath, file_name)\n",
    "            for file_name in files\n",
    "            if file_name.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "        ]\n",
    "        if images:\n",
    "            raw_name = os.path.basename(dirpath)\n",
    "            persona_name = normalize_text(raw_name)\n",
    "            persona_images.setdefault(persona_name, []).extend(images)\n",
    "            display_names[persona_name] = normalize_filename(raw_name)\n",
    "    return persona_images, display_names\n",
    "\n",
    "\n",
    "def build_ocr_map(root_path: str):\n",
    "    json_map = {}\n",
    "    if os.path.isfile(root_path):\n",
    "        file_name = os.path.basename(root_path)\n",
    "        if file_name.lower().endswith(\".json\"):\n",
    "            normalized_name = normalize_text(os.path.splitext(file_name)[0])\n",
    "            json_map[normalized_name] = root_path\n",
    "        return json_map\n",
    "\n",
    "    for dirpath, _, files in os.walk(root_path):\n",
    "        for file_name in files:\n",
    "            if file_name.lower().endswith(\".json\"):\n",
    "                normalized_name = normalize_text(os.path.splitext(file_name)[0])\n",
    "                json_map[normalized_name] = os.path.join(dirpath, file_name)\n",
    "    return json_map\n",
    "\n",
    "\n",
    "def match_json_for_persona(json_map, persona_name, threshold=70):\n",
    "    if persona_name in json_map:\n",
    "        return json_map[persona_name]\n",
    "\n",
    "    best_score, best_key = 0, None\n",
    "    for json_key in json_map:\n",
    "        score = fuzz.partial_ratio(persona_name, json_key)\n",
    "        if score > best_score:\n",
    "            best_score, best_key = score, json_key\n",
    "    if best_score >= threshold:\n",
    "        return json_map[best_key]\n",
    "    return None\n",
    "\n",
    "\n",
    "OCR_REGEX = compile_dict(OCR_PATTERNS)\n",
    "\n",
    "\n",
    "def classify(text, model, image_path):\n",
    "    text = normalize_text(text or \"\")\n",
    "\n",
    "    scores = {doc_type: 0 for doc_type in OCR_REGEX}\n",
    "    for doc_type, pattern_list in OCR_REGEX.items():\n",
    "        for pattern in pattern_list:\n",
    "            if pattern.search(text):\n",
    "                scores[doc_type] += 1\n",
    "\n",
    "    thresholds = {doc_type: max(1, len(OCR_REGEX[doc_type]) // 2) for doc_type in OCR_REGEX}\n",
    "    best_doc_type, count = max(scores.items(), key=lambda x: x[1])\n",
    "    if count >= thresholds[best_doc_type]:\n",
    "        return best_doc_type, count / len(OCR_REGEX[best_doc_type]), \"ocr_scoring\"\n",
    "\n",
    "    for doc_type, pattern_list in OCR_REGEX.items():\n",
    "        if any(pattern.search(text) for pattern in pattern_list):\n",
    "            return doc_type, 1.0, \"ocr_regex\"\n",
    "\n",
    "    simple = {doc_type: [pattern.pattern for pattern in OCR_REGEX[doc_type]] for doc_type in OCR_REGEX}\n",
    "    label_fuzzy, confidence_fuzzy = fuzzy_ocr_label(text, simple)\n",
    "    if label_fuzzy:\n",
    "        return label_fuzzy, confidence_fuzzy, \"ocr_fuzzy\"\n",
    "\n",
    "    label, confidence = visual_predict(model, image_path, strict=True)\n",
    "    if label:\n",
    "        return label, confidence, \"visual\"\n",
    "\n",
    "    return \"\", 0.0, \"none\"\n",
    "# ----------------- EXCEL -----------------\n",
    "def copy_row_format(sheet, src_row, tgt_row, max_col=13, row_height=48):\n",
    "    sheet.row_dimensions[tgt_row].height = row_height\n",
    "    thin = Side(border_style=\"thin\", color=\"000000\")\n",
    "    full_border = Border(left=thin, right=thin, top=thin, bottom=thin)\n",
    "\n",
    "    for col in range(1, max_col + 1):\n",
    "        src = sheet.cell(row=src_row, column=col)\n",
    "        tgt = sheet.cell(row=tgt_row, column=col)\n",
    "        if src.has_style:\n",
    "            tgt.font = copy(src.font)\n",
    "            tgt.fill = copy(src.fill)\n",
    "            tgt.number_format = copy(src.number_format)\n",
    "            tgt.protection = copy(src.protection)\n",
    "            tgt.alignment = copy(src.alignment)\n",
    "        tgt.border = full_border\n",
    "\n",
    "    for merged in list(sheet.merged_cells.ranges):\n",
    "        if merged.min_row == src_row == merged.max_row:\n",
    "            c1 = get_column_letter(merged.min_col)\n",
    "            c2 = get_column_letter(merged.max_col)\n",
    "            sheet.merge_cells(f\"{c1}{tgt_row}:{c2}{tgt_row}\")\n",
    "\n",
    "\n",
    "def remove_holes(sheet, hole_ranges):\n",
    "    parsed = []\n",
    "    for rng in hole_ranges:\n",
    "        min_col, min_row, max_col, max_row = range_boundaries(rng)\n",
    "        parsed.append((min_row, max_row, min_col, max_col))\n",
    "\n",
    "    to_unmerge = []\n",
    "    for merged in list(sheet.merged_cells.ranges):\n",
    "        for min_row, max_row, min_col, max_col in parsed:\n",
    "            if not (merged.max_row < min_row or merged.min_row > max_row\n",
    "                    or merged.max_col < min_col or merged.min_col > max_col):\n",
    "                to_unmerge.append(merged.coord)\n",
    "                break\n",
    "    for coord in to_unmerge:\n",
    "        sheet.unmerge_cells(coord)\n",
    "\n",
    "    for rng in hole_ranges:\n",
    "        for row in sheet[rng]:\n",
    "            for cell in row:\n",
    "                cell.value = None\n",
    "\n",
    "\n",
    "def generate_control_sheet(persona_df, persona_name):\n",
    "    output_path = os.path.join(OUTPUT_DIR_CTRL, f\"{persona_name}_hoja_de_control.xlsx\")\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"⚠️ Ya existe hoja de control para '{persona_name}', omitiendo.\")\n",
    "        return\n",
    "\n",
    "    workbook = load_workbook(TEMPLATE_PATH)\n",
    "    sheet = workbook.active\n",
    "    START_ROW = 18\n",
    "\n",
    "    holes = [\"B57:B59\", \"C57:F59\", \"D60:F60\"]\n",
    "    remove_holes(sheet, holes)\n",
    "\n",
    "    data_start = START_ROW\n",
    "    data_end = START_ROW + len(persona_df) - 1\n",
    "    for merged in list(sheet.merged_cells.ranges):\n",
    "        if (\n",
    "            merged.max_row >= data_start and merged.min_row <= data_end\n",
    "            and merged.max_col >= 1 and merged.min_col <= 7\n",
    "        ):\n",
    "            sheet.unmerge_cells(str(merged))\n",
    "\n",
    "    for index, record in enumerate(persona_df.sort_values(\"posicion\").itertuples(), start=1):\n",
    "        row = START_ROW + index - 1\n",
    "        sheet.cell(row=row, column=1, value=index)                   # A\n",
    "        sheet.cell(row=row, column=5, value=record.predicted)        # E\n",
    "        sheet.cell(row=row, column=6, value=int(record.posicion))    # F\n",
    "        sheet.cell(row=row, column=7, value=int(record.posicion))    # G\n",
    "\n",
    "    workbook.save(output_path)\n",
    "    print(\"✅ Control inmediato:\", output_path)\n",
    "\n",
    "# ----------------- MAIN -----------------\n",
    "def main():\n",
    "    os.makedirs(OUTPUT_DIR_CTRL, exist_ok=True)\n",
    "    model = YOLO(MODEL_PATH)\n",
    "\n",
    "    json_map = build_ocr_map(OCR_ROOT)\n",
    "    persona_images, display_names = find_persona_images(IMAGES_ROOT)\n",
    "\n",
    "    all_rows, global_id = [], 1\n",
    "\n",
    "    for persona_key, image_paths in persona_images.items():\n",
    "        display_name = display_names.get(persona_key, persona_key)\n",
    "        print(f\"\\nProcesando persona '{display_name}' con {len(image_paths)} imágenes…\")\n",
    "        text_lookup = {}\n",
    "        persona_records = []\n",
    "\n",
    "        json_path = match_json_for_persona(json_map, persona_key)\n",
    "        if json_path:\n",
    "            with open(json_path, encoding=\"utf-8\") as file:\n",
    "                data = json.load(file)\n",
    "            records = data if isinstance(data, list) else [data]\n",
    "            for record in records:\n",
    "                page = record.get(\"pagina\")\n",
    "                image_from_record = record.get(\"imagen\", \"\")\n",
    "                text = record.get(\"texto\", \"\")\n",
    "                if page is not None:\n",
    "                    try:\n",
    "                        num = int(page)\n",
    "                        text_lookup[num] = text\n",
    "                        text_lookup[str(num)] = text\n",
    "                    except (ValueError, TypeError):\n",
    "                        text_lookup[str(page)] = text\n",
    "                if image_from_record:\n",
    "                    text_lookup[os.path.basename(image_from_record)] = text\n",
    "\n",
    "        for image_path in sorted(image_paths, key=extract_page_number):\n",
    "            page = extract_page_number(image_path)\n",
    "            basename = os.path.basename(image_path)\n",
    "            text = (text_lookup.get(basename)\n",
    "                    or text_lookup.get(page)\n",
    "                    or text_lookup.get(str(page), \"\"))\n",
    "            label, score, layer = classify(text, model, image_path)\n",
    "\n",
    "            record = {\n",
    "                \"id\":        global_id,\n",
    "                \"persona\":   persona_key,\n",
    "                \"imagen\":    image_path,\n",
    "                \"posicion\":  page,\n",
    "                \"predicted\": label,\n",
    "                \"score\":     score,\n",
    "                \"layer\":     layer,\n",
    "            }\n",
    "            all_rows.append(record)\n",
    "            persona_records.append(record)\n",
    "            global_id += 1\n",
    "\n",
    "        if persona_records:\n",
    "            persona_df = pd.DataFrame(persona_records)\n",
    "            persona_df[\"correct\"] = persona_df[\"persona\"] == persona_df[\"predicted\"]\n",
    "            generate_control_sheet(persona_df, display_name)\n",
    "\n",
    "    print(\"\\n⏳ Generando DataFrame y guardando\", OUTPUT_FILE)\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    df[\"correct\"] = df[\"persona\"] == df[\"predicted\"]\n",
    "    df.to_excel(OUTPUT_FILE, index=False)\n",
    "    print(\"✅ Consolidado en\", OUTPUT_FILE)\n",
    "\n",
    "    START_ROW = 18\n",
    "    for persona_name, group in df[df[\"predicted\"] != \"\"].groupby(\"persona\"):\n",
    "        workbook = load_workbook(TEMPLATE_PATH)\n",
    "        sheet = workbook.active\n",
    "\n",
    "        footer = None\n",
    "        for row in sheet.iter_rows(min_row=START_ROW, max_row=sheet.max_row):\n",
    "            for cell in row:\n",
    "                if isinstance(cell.value, str) and \"NOMBRE Y APELLIDOS\" in cell.value.upper():\n",
    "                    footer = cell.row\n",
    "                    break\n",
    "            if footer:\n",
    "                break\n",
    "        if not footer:\n",
    "            footer = START_ROW + 38\n",
    "\n",
    "        template_rows = footer - START_ROW\n",
    "        num_pages = len(group)\n",
    "        if num_pages > template_rows:\n",
    "            extra = num_pages - template_rows\n",
    "            sheet.insert_rows(footer, amount=extra)\n",
    "            src_row = footer - 1\n",
    "            for i in range(extra):\n",
    "                dst_row = footer + i\n",
    "                sheet.row_dimensions[dst_row].height = sheet.row_dimensions[src_row].height\n",
    "                for col in (5, 6, 7):\n",
    "                    src = sheet.cell(row=src_row, column=col)\n",
    "                    dst = sheet.cell(row=dst_row, column=col)\n",
    "                    dst.font = copy(src.font)\n",
    "                    dst.border = copy(src.border)\n",
    "                    dst.fill = copy(src.fill)\n",
    "                    dst.alignment = copy(src.alignment)\n",
    "                    dst.number_format = src.number_format\n",
    "\n",
    "        for index, record in enumerate(group.sort_values(\"posicion\").itertuples()):\n",
    "            row = START_ROW + index\n",
    "            sheet.cell(row=row, column=5, value=record.predicted)\n",
    "            sheet.cell(row=row, column=6, value=int(record.posicion))\n",
    "            sheet.cell(row=row, column=7, value=int(record.posicion))\n",
    "\n",
    "        display_name = display_names.get(persona_name, persona_name)\n",
    "        out = os.path.join(OUTPUT_DIR_CTRL, f\"{display_name}_hoja_de_control.xlsx\")\n",
    "        workbook.save(out)\n",
    "        print(\"✅ Control:\", out)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clasificador_docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
